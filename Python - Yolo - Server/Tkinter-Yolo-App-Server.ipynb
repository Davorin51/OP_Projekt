{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from threading import Thread\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# your server code\n",
    "def run_server(ip, port):\n",
    "    # convert the port from string to int\n",
    "    port = int(port)\n",
    "\n",
    "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    server_socket.bind((ip, port))\n",
    "    server_socket.listen(1)\n",
    "    net = cv2.dnn.readNet('yolov3.cfg', \"/home/davorin/Documents/OP/yolov3.weights\")\n",
    "\n",
    "\n",
    "    def recv_all(sock, n):\n",
    "    # Helper function to receive n bytes or return None if EOF is hit\n",
    "        data = bytearray()\n",
    "        while len(data) < n:\n",
    "            packet = sock.recv(n - len(data))\n",
    "            if not packet:\n",
    "                return None\n",
    "            data.extend(packet)\n",
    "        return data\n",
    "    \n",
    "    def calculate_ap(precision, recall):\n",
    "    # Sort precision and recall in descending order of confidence scores\n",
    "        sorted_indices = np.argsort(-precision)\n",
    "        sorted_precision = precision[sorted_indices]\n",
    "        sorted_recall = recall[sorted_indices]\n",
    "\n",
    "    # Compute interpolated precision values\n",
    "        for i in range(len(sorted_precision) - 2, -1, -1):\n",
    "            sorted_precision[i] = max(sorted_precision[i], sorted_precision[i + 1])\n",
    "\n",
    "    # Compute area under the precision-recall curve\n",
    "        ap = np.sum((sorted_recall[1:] - sorted_recall[:-1]) * sorted_precision[:-1])\n",
    "\n",
    "        return ap\n",
    "    \n",
    "    def calculate_iou(boxA, boxB):\n",
    "    # Calculate coordinates of the intersection rectangle\n",
    "        xA = max(boxA[0], boxB[0])\n",
    "        yA = max(boxA[1], boxB[1])\n",
    "        xB = min(boxA[2], boxB[2])\n",
    "        yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    # Compute the intersection area\n",
    "        intersection_area = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "\n",
    "    # Compute the union area\n",
    "        boxA_area = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "        boxB_area = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "        union_area = boxA_area + boxB_area - intersection_area\n",
    "\n",
    "    # Calculate IoU\n",
    "        iou = intersection_area / union_area\n",
    "\n",
    "        return iou\n",
    "    \n",
    "    while True:\n",
    "        print(\"Waiting for a connection...\")\n",
    "        client_socket, addr = server_socket.accept()\n",
    "        print(f\"Accepted connection from {addr}\")\n",
    "\n",
    "    # receive the image data\n",
    "        length_prefix = recv_all(client_socket, 4)  # assuming that the length is sent as 4 bytes (a 32-bit int)\n",
    "        if length_prefix is None:\n",
    "            print('Length prefix not received')\n",
    "        else:\n",
    "            length = int.from_bytes(length_prefix, 'little')  # convert bytes to int\n",
    "            data = recv_all(client_socket, length)  # receive the rest of the data\n",
    "            if data is None:\n",
    "                print('Image not received')\n",
    "            else:\n",
    "                print(\"Loading classes\")\n",
    "                with open(\"coco.names\", \"r\") as f:\n",
    "                    classes = [line.strip() for line in f.readlines()]\n",
    "                print(\"Classes loaded\")\n",
    "\n",
    "            # convert the bytes to an image\n",
    "                image_stream = BytesIO(data)\n",
    "                image = Image.open(image_stream)\n",
    "                image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "            # use the YOLO model to perform object detection\n",
    "                print(\"Image is being processed\")\n",
    "                height, width = image.shape[:2]\n",
    "                blob = cv2.dnn.blobFromImage(image, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "                net.setInput(blob)\n",
    "                start_time = time.time()\n",
    "                outs = net.forward(net.getUnconnectedOutLayersNames())\n",
    "                end_time = time.time()\n",
    "                execution_time = end_time - start_time\n",
    "                print(\"Execution Time: {:.2f} seconds\".format(execution_time))\n",
    "\n",
    "                print(\"Inference running\")\n",
    "           \n",
    "            # process the results\n",
    "                class_ids = []\n",
    "                confidences = []\n",
    "                boxes = []\n",
    "                for out in outs:\n",
    "                    for detection in out:\n",
    "                        scores = detection[5:]\n",
    "                        class_id = np.argmax(scores)\n",
    "                        confidence = scores[class_id]\n",
    "                        if confidence > 0.5:\n",
    "                            center_x = int(detection[0] * width)\n",
    "                            center_y = int(detection[1] * height)\n",
    "                            w = int(detection[2] * width)\n",
    "                            h = int(detection[3] * height)\n",
    "                            x = int(center_x - w / 2)\n",
    "                            y = int(center_y - h / 2)\n",
    "                            boxes.append([x, y, w, h])\n",
    "                            confidences.append(float(confidence))\n",
    "                            class_ids.append(class_id)\n",
    "                print(\"Coordinates are here:\")\n",
    "\n",
    "            # apply non-maxima suppression to get the most relevant detections\n",
    "                indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "            # create a list to store all the detection results\n",
    "                results = []\n",
    "\n",
    "                if len(indices) > 0:\n",
    "                    for i in indices.flatten():  # flatten the list to handle single/multiple indices\n",
    "                        box = boxes[i]\n",
    "                        x, y, w, h = box[0], box[1], box[2], box[3]\n",
    "                        label = str(classes[class_ids[i]])\n",
    "                        result = {'label': label, 'x': x, 'y': y, 'w': w, 'h': h}\n",
    "                        results.append(result)\n",
    "\n",
    "                num_objects = len(results)\n",
    "                print(\"Number of objects:\")\n",
    "                print(num_objects)\n",
    "            # Calculate Average Precision (AP)\n",
    "                if len(indices) > 0:\n",
    "                    precision = np.ones(len(indices))\n",
    "                    recall = np.arange(1, len(indices) + 1) / len(indices)\n",
    "                    ap = calculate_ap(precision, recall)\n",
    "                    print(\"Average Precision (AP):\", ap)\n",
    "            \n",
    "            # Add execution time and AP to the results dictionary\n",
    "                    results.append({'execution_time': execution_time, 'ap': ap, 'num_objects': num_objects})\n",
    "\n",
    "                print(results)\n",
    "        # send the detection results back to the client\n",
    "            client_socket.sendall(json.dumps(results).encode())\n",
    "\n",
    "        client_socket.close()\n",
    "\n",
    "    \n",
    "\n",
    "    # add the rest of your server code here...\n",
    "\n",
    "class VisionSphereApp(tk.Tk):\n",
    "    def __init__(self):\n",
    "        self.root = tk.Tk()\n",
    "        self.root.title(\"Vision Sphere Application\")\n",
    "        self.root.geometry('600x400')  # Set the window size to 600x400\n",
    "\n",
    "        self.ip_entry = tk.Entry(self.root, width=15)\n",
    "        self.ip_entry.pack(padx=20, pady=20)  # Added padding for a cleaner layout\n",
    "\n",
    "        self.port_entry = tk.Entry(self.root, width=5)\n",
    "        self.port_entry.pack(padx=20, pady=20)\n",
    "\n",
    "        self.start_button = tk.Button(self.root, text=\"Start server\", command=self.start_server)\n",
    "        self.start_button.pack(padx=20, pady=20)\n",
    "\n",
    "    def start_server(self):\n",
    "        ip = self.ip_entry.get()\n",
    "        port = self.port_entry.get()\n",
    "\n",
    "        if not ip or not port:\n",
    "            messagebox.showinfo(\"Missing info\", \"IP and Port are required to start the server.\")\n",
    "        else:\n",
    "            thread = Thread(target=run_server, args=(ip, port))\n",
    "            thread.start()\n",
    "            messagebox.showinfo(\"Server status\", \"Server started.\")\n",
    "    \n",
    "    def run(self):\n",
    "        self.root.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/davorin/anaconda3/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/davorin/anaconda3/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_5951/1224416876.py\", line 18, in run_server\n",
      "OSError: [Errno 98] Address already in use\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for a connection...\n",
      "Accepted connection from ('192.168.0.215', 58334)\n",
      "Loading classes\n",
      "Classes loaded\n",
      "Image is being processed\n",
      "Execution Time: 0.33 seconds\n",
      "Inference running\n",
      "Coordinates are here:\n",
      "Number of objects:\n",
      "9\n",
      "Average Precision (AP): 0.8888888888888888\n",
      "[{'label': 'car', 'x': 284, 'y': 207, 'w': 181, 'h': 146}, {'label': 'car', 'x': 557, 'y': 201, 'w': 259, 'h': 155}, {'label': 'car', 'x': 464, 'y': 215, 'w': 124, 'h': 123}, {'label': 'person', 'x': 155, 'y': 150, 'w': 135, 'h': 221}, {'label': 'car', 'x': 757, 'y': 204, 'w': 110, 'h': 139}, {'label': 'car', 'x': 1, 'y': 158, 'w': 92, 'h': 195}, {'label': 'car', 'x': 421, 'y': 224, 'w': 53, 'h': 77}, {'label': 'bicycle', 'x': 196, 'y': 298, 'w': 96, 'h': 146}, {'label': 'truck', 'x': 104, 'y': 166, 'w': 100, 'h': 143}, {'execution_time': 0.32871508598327637, 'ap': 0.8888888888888888, 'num_objects': 9}]\n",
      "Waiting for a connection...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "app = VisionSphereApp()\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
